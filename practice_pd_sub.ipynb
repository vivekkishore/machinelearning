{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNtAto8GwpocqQC051yWDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekkishore/machinelearning/blob/main/practice_pd_sub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4XaWkTO5nwn"
      },
      "outputs": [],
      "source": [
        "from abc import ABC,abstractmethod\n",
        "class shape(ABC):\n",
        "  def __init__(self,shapetype,color):\n",
        "    self.shapetype=shapetype\n",
        "    self.color=color\n",
        "\n",
        "  @abstractmethod\n",
        "  def area(self):\n",
        "    pass\n",
        "  def get_color(self):\n",
        "    return self.color\n",
        "  def get_shapetype(self):\n",
        "    return self.shapetype\n",
        "\n",
        "class square(shape):\n",
        "  def __init__(self,side,color):\n",
        "    self.side=side\n",
        "    super().__init__('square',color)\n",
        "  def area(self):\n",
        "    return self.side*self.side\n",
        "\n",
        "class circle(shape):\n",
        "  def __init__(self,radius,color):\n",
        "    self.radius=radius\n",
        "    super().__init__('circle',color)\n",
        "  def area(self):\n",
        "    return 3.14*self.radius*self.radius\n",
        "\n",
        "class rectangle(shape):\n",
        "  def __init__(self,length,width,color):\n",
        "    self.length=length\n",
        "    self.width=width\n",
        "    super().__init__('rectangle',color)\n",
        "  def area(self):\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sq1=square(5,'red')\n",
        "print(sq1.area())\n",
        "print(sq1.get_color())\n",
        "print(sq1.get_shapetype())"
      ],
      "metadata": {
        "id": "64TFtFhN5unp",
        "outputId": "bf2ab1f0-8149-4071-f005-c4999488fc9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "red\n",
            "square\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Agent and worflows"
      ],
      "metadata": {
        "id": "FpqCLhLsovnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qU langchain-groq\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "os.environ['GROQ_API_KEY']=userdata.get('groq_key')\n",
        "\n",
        "model=ChatGroq(model='llama-3.3-70b-versatile')\n",
        "\n",
        "basic_prompt = \"\"\"\n",
        "You are a knowledgeable AI assistant specializing in trend analysis and reporting.\n",
        "Please address the following inquiry:\n",
        "Query: {query}\n",
        "\"\"\"\n",
        "\n",
        "template_obj = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=basic_prompt\n",
        ")\n",
        "\n",
        "# new_template= template_obj.format(variable=variable)\n",
        "# new_template\n",
        "\n",
        "llmchain= template_obj | model | StrOutputParser()\n",
        "\n",
        "llmchain.invoke({'query':'who are you?'})\n",
        "\n"
      ],
      "metadata": {
        "id": "AWsJ_V5M5ur3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7b84271b-1dd4-4133-b707-dbc4f691dadb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am a knowledgeable AI assistant specializing in trend analysis and reporting. My primary function is to provide insightful and data-driven information on various trends across multiple industries and domains. I utilize advanced natural language processing and machine learning algorithms to analyze large datasets, identify patterns, and forecast future trends.\\n\\nMy capabilities include:\\n\\n1. **Trend identification**: I can recognize and report on emerging trends, as well as track the evolution of existing ones.\\n2. **Data analysis**: I can process and analyze large datasets to extract relevant insights and patterns.\\n3. **Forecasting**: I can use statistical models and machine learning algorithms to predict future trends and outcomes.\\n4. **Reporting**: I can generate comprehensive and easy-to-understand reports on trends, including charts, graphs, and other visualizations.\\n\\nMy areas of expertise include, but are not limited to:\\n\\n* Market trends\\n* Technological advancements\\n* Social media trends\\n* Economic trends\\n* Environmental trends\\n* Cultural trends\\n\\nI am here to assist you with any questions or inquiries you may have regarding trends and trend analysis. Please feel free to ask me anything, and I will do my best to provide you with accurate and insightful information.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKwdXD2CeSPp",
        "outputId": "0b770290-9c5b-4372-aa59-03cfe2188395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['query', 'variable'], input_types={}, partial_variables={}, template='\\nYou are a knowledgeable AI assistant specializing in trend analysis and reporting.\\nPlease address the following inquiry: {variable}\\nQuery: {query}\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzjqxFDYynun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# messages = [\n",
        "#     SystemMessage(\"Translate the following from English into Italian\"),\n",
        "#     HumanMessage(\"hi!\"),\n",
        "# ]\n",
        "# model.invoke(messages)\n",
        "\n",
        "# from groq import Groq\n",
        "\n",
        "# client = Groq()\n",
        "# completion = client.chat.completions.create(\n",
        "#     model=\"llama-3.3-70b-versatile\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": \"who are you?\"\n",
        "#         }\n",
        "#     ],\n",
        "#     temperature=1,\n",
        "#     max_tokens=1024,\n",
        "#     top_p=1,\n",
        "#     stream=False,\n",
        "#     stop=None,\n",
        "# )\n",
        "\n",
        "# print(completion.choices[0].message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QrNhrMEtPzC",
        "outputId": "0e407c9a-3ade-4aff-82cb-2fe92490fb63"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FvfcwBtOtPp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D9JX_mQivWss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ax8j3aEwvWpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MsYFGyjVvWnL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}