{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnY8Sj4j7IE6hupNBun90z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekkishore/machinelearning/blob/main/llamaindex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLama index"
      ],
      "metadata": {
        "id": "0qDz3eH74MKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Query GPT with LLama index"
      ],
      "metadata": {
        "id": "rxI1PrhiKwli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install llama-index\n",
        "# !pip install llama-index-llms-azure-openai\n",
        "# !pip install python-dotenv"
      ],
      "metadata": {
        "id": "Dea_T-YJK1yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureOpenAI(\n",
        "    model=azure_gpt_model_name,\n",
        "    deployment_name=gpt_deployment_name,\n",
        "    api_key=azure_openai_key,\n",
        "    azure_endpoint=azure_openai_endpoint,\n",
        "    api_version=api_version,\n",
        ")\n",
        "response = llm.complete(\"The sky is blue\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd0NdpUgK2Bh",
        "outputId": "9c43d42e-dbfd-4c7b-d548-957442b34ffb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, that is correct. The sky appears blue during the day due to the scattering of sunlight by the Earth's atmosphere.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "messages=[\n",
        "  ChatMessage(role='system',content='You are funny and helpful bot'\n",
        "    ),\n",
        "    ChatMessage(role='user',content='why is sky blue?')\n",
        "]\n",
        "\n",
        "response=llm.chat(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikzm5A6JK2Es",
        "outputId": "823fbe3c-7455-4269-f81a-21694a5b55e4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: Well, the sky is blue because it's trying to be cool and stand out from all the other colors. It's like the sky's way of saying, \"Hey, look at me, I'm the coolest color around!\" Plus, blue is just a really calming and peaceful color, so it's the perfect choice for the sky.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using LLama index to query list of JSON"
      ],
      "metadata": {
        "id": "WlgNLgs4DICc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF2mJWTtg8td"
      },
      "outputs": [],
      "source": [
        "# !pip install llama-index\n",
        "# !pip install llama-index-llms-azure-openai\n",
        "# !pip install llama-index-embeddings-azure-openai\n",
        "# !pip install sqlite-utils\n",
        "# !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[\n",
        "    {'name':'charls','age':10,'city':'Newyork'},\n",
        "    {'name':'bob','age':15,'city':'delhi'},\n",
        "    {'name':'alice','age':20,'city':'mumbai'},\n",
        "     {'name':'john','age':25,'city':'chicago'},\n",
        "     {'name':'maddie','age':21,'city':'pune'}\n",
        "     ]"
      ],
      "metadata": {
        "id": "lAMizLp94KLc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "from dotenv import dotenv_values\n",
        "config = dotenv_values(\".env\")\n",
        "\n",
        "\n",
        "azure_openai_key = config[\"API_KEY\"]\n",
        "azure_openai_endpoint = config[\"ENDPOINT\"]\n",
        "azure_gpt_model_name=config[\"GPT_Model_Name\"]\n",
        "gpt_deployment_name=config[\"Deployment_Name\"]\n",
        "api_version=config['Model_Version']\n",
        "azure_embed_model_name=config[\"Embed_Model_Name\"]\n",
        "embedding_deployment_name=config[\"Embed_Deployment\"]\n",
        "\n",
        "llm = AzureOpenAI(\n",
        "    model=azure_gpt_model_name,\n",
        "    deployment_name=gpt_deployment_name,\n",
        "    api_key=azure_openai_key,\n",
        "    azure_endpoint=azure_openai_endpoint,\n",
        "    api_version=api_version,\n",
        ")\n",
        "\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=azure_embed_model_name,\n",
        "    deployment_name=embedding_deployment_name,\n",
        "    api_key=azure_openai_key,\n",
        "    azure_endpoint=azure_openai_endpoint,\n",
        "    api_version=api_version,\n",
        ")"
      ],
      "metadata": {
        "id": "3o0B9vJk4KOK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine import JSONalyzeQueryEngine\n",
        "#JSON data is being converted to SQL first\n",
        "engine=JSONalyzeQueryEngine(\n",
        "    list_of_dict=data,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Rk3x6pq3FwcY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=engine.query(\"Do anyone live in city bangalore?\")\n",
        "result"
      ],
      "metadata": {
        "id": "pAujX9VZFwe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9b9f46-0700-4248-e49c-c70ead58dc66"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;32mQuery: Do anyone live in city bangalore?\n",
            "\u001b[0m\u001b[1;3;34mSQL Query: SELECT COUNT(*) FROM items WHERE city = 'bangalore'\n",
            "\u001b[0m\u001b[1;3;36mTable Schema: {'name': <class 'str'>, 'age': <class 'int'>, 'city': <class 'str'>}\n",
            "\u001b[0m\u001b[1;3;33mSQL Response: [{'COUNT(*)': 0}]\n",
            "\u001b[0m\u001b[1;3;35mResponse: No, no one lives in the city of Bangalore.\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(response='No, no one lives in the city of Bangalore.', source_nodes=[], metadata={'sql_query': \"SELECT COUNT(*) FROM items WHERE city = 'bangalore'\", 'table_schema': \"{'name': <class 'str'>, 'age': <class 'int'>, 'city': <class 'str'>}\"})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_HgpU7wIPkc",
        "outputId": "a37da6c6-cc2e-41fb-da34-1fd87bf1c13a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No, no one lives in the city of Bangalore.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Query text file with LLamma index\n",
        "\n"
      ],
      "metadata": {
        "id": "eHWPBu1VM4WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index docx2txt pypdf python-dotenv llama-index-embeddings-azure-openai llama-index-llms-azure-openai"
      ],
      "metadata": {
        "id": "b8zArcawFwgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "from dotenv import dotenv_values\n",
        "\n",
        "config=dotenv_values(\".env\")\n",
        "\n",
        "azure_openai_key = config[\"API_KEY\"]\n",
        "azure_openai_endpoint = config[\"ENDPOINT\"]\n",
        "azure_gpt_model_name=config[\"GPT_Model_Name\"]\n",
        "gpt_deployment_name=config[\"Deployment_Name\"]\n",
        "api_version=config['Model_Version']\n",
        "azure_embed_model_name=config[\"Embed_Model_Name\"]\n",
        "embedding_deployment_name=config[\"Embed_Deployment\"]\n",
        "\n",
        "llm = AzureOpenAI(\n",
        "    model=azure_gpt_model_name,\n",
        "    deployment_name=gpt_deployment_name,\n",
        "    api_key=azure_openai_key,\n",
        "    azure_endpoint=azure_openai_endpoint,\n",
        "    api_version=api_version,\n",
        ")\n",
        "\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=azure_embed_model_name,\n",
        "    deployment_name=embedding_deployment_name,\n",
        "    api_key=azure_openai_key,\n",
        "    azure_endpoint=azure_openai_endpoint,\n",
        "    api_version=api_version,\n",
        ")"
      ],
      "metadata": {
        "id": "lyZ6v74fFwkc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "VFb2foSm9_Sc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "\n",
        "documents = SimpleDirectoryReader( input_files=[\"sample1.txt\"]).load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "oXfPrw1qiVNB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"What is SP initiated integration?\"\n",
        "query_engine=index.as_query_engine(response_mode=  )\n",
        "answer=query_engine.query(query)\n",
        "\n",
        "# print(answer.get_formatted_sources())\n",
        "print(\"query was:\", query)\n",
        "print(\"answer is:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMFRAWHfNlcR",
        "outputId": "c908f3ba-4a88-4b9a-df2a-ea38a6bd5492"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query was: What is SP initiated integration?\n",
            "answer is: SP-initiated integration is a login process in which a user navigates to the vendor application, and then the application redirects the unauthenticated user to Azure AD for authentication. After the user is authenticated, they are redirected back to the application with an authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "template=(\n",
        "    \"I have provided the context below \\n\"\n",
        "    \"-------------------------\\n\"\n",
        "    \"You are a funny bot who always starts the answer with one joke \\n\"\n",
        "    \"---------------------------------- \\n\"\n",
        "    \"Given this context, please answer this question: {query_str} \\n\"\n",
        ")\n",
        "\n",
        "query=\"What is SP initiated integration?\"\n",
        "qa_prompt=PromptTemplate(template)\n",
        "\n",
        "prompt=qa_prompt.format(query_str=query)\n",
        "# print(prompt)\n",
        "\n",
        "answer=query_engine.query(prompt)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "r3MCFHBVKqE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561f526c-08f8-4ca3-ffab-491b74aa9dc7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the scarecrow win an award? Because he was outstanding in his field! \n",
            "\n",
            "SP-initiated integration is a login process in which a user navigates to the vendor application, which then redirects the user to Azure AD for authentication. After authentication, the user is redirected back to the application with an authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j353NrG9KqIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBb9oTmmiVQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Query pdf with LLama index"
      ],
      "metadata": {
        "id": "-PGr0BSbPhSD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcMLZ3kYPgN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lUD9pE7DPgQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CK5akAvsPgUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}